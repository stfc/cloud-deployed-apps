stfc-cloud-openstack-cluster:
  openstack-cluster:
    addons:
      monitoring:
        enabled: true
        lokiStack:
          enabled: false
        kubePrometheusStack:
          release:
            values:
              alertmanager:
                config:
                  global:
                    resolve_timeout: 5m
                    smtp_require_tls: true
                    opsgenie_api_url: 'https://api.opsgenie.com/'


                  route:
                    # we need a null reciever to workaround azimuth addon enforced defaults 
                    # https://github.com/azimuth-cloud/capi-helm-charts/blob/main/charts/cluster-addons/templates/monitoring/kube-prometheus-stack.yaml#L41-L44
                    receiver: "null"
                    routes:

                        # mute watchdog alert
                        #   - this should always be firing
                        # mute infoinhibitor alert
                        #   - not useful by itself
                        #   - if this is firing, we're suppressing severity=info alerts
                        #   - infoinhibitor rules should be automatically configured
                      - matchers:
                          - alertname=~"Watchdog|InfoInhibitor" 
                        continue: false

                      # Route 1: alerts WITH namespace label - group by instance
                      - matchers:
                          - namespace=~".+"
                        group_by: ['namespace', 'severity']
                        receiver: 'with-namespace-receiver'
                        continue: false

                      - receiver: "default-receiver"
                        group_by: ["cluster"]
                        group_wait: 30s
                        group_interval: 5m
                        repeat_interval: 2h
                        active_time_intervals:
                          - officehours



                  inhibit_rules:
                    # mute warning/info alerts on same service if a critical alert is firing - less noise
                    - source_matchers:
                        - severity = "critical"
                      target_matchers:
                        - severity = "warning"
                      equal: [cluster, alertname]

                  time_intervals:
                    - name: officehours
                      time_intervals:
                        - times:
                            - start_time: 08:30
                              end_time: 17:00
                          weekdays: ["monday:friday"]
                          location: "Europe/London"

                  receivers:
                    - name: "null"
                    - name: default-receiver
                      opsgenie_configs:
                        - send_resolved: true
                          message: >- 
                            {%- raw %}
                            "{{ .Status | toUpper }}{{ if eq .Status "firing" }} [{{.CommonLabels.env}}/{{ .CommonLabels.cluster }}: {{ .CommonLabels.severity | toUpper }}] {{ .Alerts.Firing | len }}{{ end }} {{.CommonLabels.alertname}} alert(s)"
                            {%- endraw %}
                          description: >-
                              {%- raw %}
                              {{ if gt (len .Alerts.Firing) 0 -}}
                              Alerts Firing:
                              {{ template "__text_alert_list" .Alerts.Firing }}
                              {{- end }}
                              {%- endraw %}
                          tags: >- 
                              {%- raw %}
                              "{{- if eq .CommonLabels.env "prod" -}}stfc-production{{- else -}}stfc-development{{- end }}"
                              {%- endraw %}
                          entity: >-
                              {%- raw %}
                              "{{- if eq .CommonLabels.env "prod" -}}stfc-production{{- else -}}stfc-development{{- end }}"
                              {%- endraw %}
                          

                    - name: with-namespace-receiver
                      opsgenie_configs:
                        - send_resolved: true
                          message: >- 
                            {%- raw %}
                            "{{ .Status | toUpper }}{{ if eq .Status "firing" }} [{{.CommonLabels.env}}/{{ .CommonLabels.cluster }}: {{ .CommonLabels.severity | toUpper }}] {{ .Alerts.Firing | len }}{{ end }} alert(s) for {{.CommonLabels.namespace}}"
                            {%- endraw %}
                          description: >-
                            {%- raw %}
                            {{ if gt (len .Alerts.Firing) 0 -}}
                            Alerts Firing:
                            {{ template "__text_alert_list" .Alerts.Firing }}
                            {{- end }}
                            {%- endraw %}
                          tags: >- 
                            {%- raw %}
                            "{{- if eq .CommonLabels.env "prod" -}}stfc-production{{- else -}}stfc-development{{- end }}"
                            {%- endraw %}
                          entity: >-
                            {%- raw %}
                            "{{- if eq .CommonLabels.env "prod" -}}stfc-production{{- else -}}stfc-development{{- end }}"
                            {%- endraw %}
                          
                  templates:
                    - "/etc/alertmanager/config/*.tmpl"
